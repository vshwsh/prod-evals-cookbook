{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 1: Golden Sets â€” Your Foundation for AI Quality\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ What You'll Learn\n",
    "\n",
    "By the end of this walkthrough, you'll understand:\n",
    "\n",
    "1. **What golden sets are** and why they're the foundation of every eval framework\n",
    "2. **How golden sets work** behind the scenes â€” what actually happens when you run a test\n",
    "3. **How to write effective test cases** that catch real issues\n",
    "4. **Where golden sets fit** in the maturity of an eval framework\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š Understanding Golden Sets\n",
    "\n",
    "### What Are Golden Sets?\n",
    "\n",
    "**Golden sets are curated input/output pairs that define what \"correct\" looks like for your AI system.** They are the ground truthâ€”manually verified examples that establish baseline correctness.\n",
    "\n",
    "Think of golden sets like unit tests for traditional software:\n",
    "\n",
    "| Traditional Software | AI System (Golden Sets) |\n",
    "|---------------------|------------------------|\n",
    "| `assertEqual(add(2, 3), 5)` | Query: \"What's our PTO policy?\" |\n",
    "| Expected output: `5` | Must contain: \"15 days\", \"annual\" |\n",
    "| Exact match required | Semantic match + constraints |\n",
    "\n",
    "### Why \"Golden\"?\n",
    "\n",
    "The term \"golden\" comes from \"golden master\" testingâ€”a technique where you capture a known-good output and compare future outputs against it. These are your **gold standard** reference answers.\n",
    "\n",
    "### Why Start Here?\n",
    "\n",
    "Golden sets are Stage 1 because they provide:\n",
    "\n",
    "1. **Ground truth establishment** â€” You manually verify these are correct\n",
    "2. **Fast regression detection** â€” Run in minutes, catch breakages immediately  \n",
    "3. **Easy debugging** â€” When one fails, you know exactly what went wrong\n",
    "4. **Team alignment** â€” Everyone agrees on what \"correct\" means\n",
    "\n",
    "Without golden sets, you're flying blindâ€”you don't actually know if your agent is working correctly.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ—ï¸ Where Golden Sets Fit: The Eval Maturity Model\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    EVAL FRAMEWORK MATURITY                      â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                 â”‚\n",
    "â”‚  Stage 5: Experiments      â† Compare configurations            â”‚\n",
    "â”‚      â–²                                                          â”‚\n",
    "â”‚  Stage 4: Rubrics          â† Multi-dimensional scoring         â”‚\n",
    "â”‚      â–²                                                          â”‚\n",
    "â”‚  Stage 3: Replay Harnesses â† Reproducibility + rich metrics    â”‚\n",
    "â”‚      â–²                                                          â”‚\n",
    "â”‚  Stage 2: Labeled Scenariosâ† Coverage mapping                  â”‚\n",
    "â”‚      â–²                                                          â”‚\n",
    "â”‚  â˜… Stage 1: GOLDEN SETS â˜…  â† Baseline correctness (YOU ARE HERE)â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "**Golden sets are the foundation.** Every subsequent stage builds on this. If your golden sets are weak, everything above will be unreliable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” Behind the Scenes: How Golden Sets Work\n",
    "\n",
    "Let's trace what happens when you run a golden set evaluation:\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    GOLDEN SET EVALUATION FLOW                         â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                       â”‚\n",
    "â”‚  1. LOAD TEST CASE                                                    â”‚\n",
    "â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚\n",
    "â”‚     â”‚ id: gs-001                                               â”‚      â”‚\n",
    "â”‚     â”‚ query: \"What is our remote work policy?\"                 â”‚      â”‚\n",
    "â”‚     â”‚ expected_tools: [vector_search]                          â”‚      â”‚\n",
    "â”‚     â”‚ must_contain: [\"remote\", \"core hours\", \"$500\"]           â”‚      â”‚\n",
    "â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚\n",
    "â”‚                            â”‚                                          â”‚\n",
    "â”‚                            â–¼                                          â”‚\n",
    "â”‚  2. RUN THE AGENT                                                     â”‚\n",
    "â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚\n",
    "â”‚     â”‚ ask_acme_with_trace(query)                               â”‚      â”‚\n",
    "â”‚     â”‚   â†’ LLM decides which tool to use                        â”‚      â”‚\n",
    "â”‚     â”‚   â†’ Calls vector_search(\"remote work policy\")            â”‚      â”‚\n",
    "â”‚     â”‚   â†’ Retrieves remote_work_policy.md                      â”‚      â”‚\n",
    "â”‚     â”‚   â†’ LLM generates response from retrieved docs           â”‚      â”‚\n",
    "â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚\n",
    "â”‚                            â”‚                                          â”‚\n",
    "â”‚                            â–¼                                          â”‚\n",
    "â”‚  3. CAPTURE TRACE                                                     â”‚\n",
    "â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚\n",
    "â”‚     â”‚ trace = {                                                â”‚      â”‚\n",
    "â”‚     â”‚   \"response\": \"Our remote work policy includes...\",     â”‚      â”‚\n",
    "â”‚     â”‚   \"tool_calls\": [{\"tool\": \"vector_search\", ...}]         â”‚      â”‚\n",
    "â”‚     â”‚ }                                                        â”‚      â”‚\n",
    "â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚\n",
    "â”‚                            â”‚                                          â”‚\n",
    "â”‚                            â–¼                                          â”‚\n",
    "â”‚  4. RUN CHECKS                                                        â”‚\n",
    "â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚\n",
    "â”‚     â”‚ âœ“ Tool Check:     Is vector_search in actual_tools?      â”‚      â”‚\n",
    "â”‚     â”‚ âœ“ Source Check:   Is remote_work_policy.md mentioned?    â”‚      â”‚\n",
    "â”‚     â”‚ âœ“ Content Check:  Are \"remote\", \"core hours\" found?      â”‚      â”‚\n",
    "â”‚     â”‚ âœ“ Negative Check: Is \"I don't know\" absent?              â”‚      â”‚\n",
    "â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚\n",
    "â”‚                            â”‚                                          â”‚\n",
    "â”‚                            â–¼                                          â”‚\n",
    "â”‚  5. REPORT RESULT                                                     â”‚\n",
    "â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚\n",
    "â”‚     â”‚ gs-001: PASS âœ“                                           â”‚      â”‚\n",
    "â”‚     â”‚   Tools: âœ“  Sources: âœ“  Content: âœ“  Negative: âœ“          â”‚      â”‚\n",
    "â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚\n",
    "â”‚                                                                       â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "**Key insight:** We're not checking if the response is \"exactly right\"â€”we're checking if it meets a set of **constraints** that define correctness. This is essential for AI systems where the exact wording will vary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../setup_agent\")\n",
    "\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from evaluator import run_test_case, load_golden_set, check_tools, check_must_contain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’» Hands-On: Understanding Golden Set Structure\n",
    "\n",
    "Now let's see this in action. First, let's examine how a golden set test case is structured:\n",
    "\n",
    "### Anatomy of a Test Case\n",
    "\n",
    "Each test case defines constraints that a correct response must satisfy:\n",
    "\n",
    "| Field | Purpose | Example |\n",
    "|-------|---------|---------|\n",
    "| `id` | Unique identifier for tracking | `gs-001` |\n",
    "| `query` | The input question | \"What is our remote work policy?\" |\n",
    "| `expected_tools` | Which tools should be used | `[\"vector_search\"]` |\n",
    "| `expected_sources` | Which documents should be cited | `[\"remote_work_policy.md\"]` |\n",
    "| `must_contain` | Keywords that must appear | `[\"remote\", \"core hours\"]` |\n",
    "| `must_not_contain` | Phrases that indicate failure | `[\"I don't know\"]` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 15 test cases\n",
      "\n",
      "Example test case:\n",
      "----------------------------------------\n",
      "id: gs-001\n",
      "category: vector_search\n",
      "query: What is our remote work policy?\n",
      "expected_tools: ['vector_search']\n",
      "expected_sources: ['remote_work_policy.md']\n",
      "must_contain: ['remote', 'core hours', '10']\n",
      "must_not_contain: [\"I don't know\", 'I cannot find']\n"
     ]
    }
   ],
   "source": [
    "# Load the golden set\n",
    "test_cases = load_golden_set()\n",
    "print(f\"Loaded {len(test_cases)} test cases\\n\")\n",
    "\n",
    "# Look at the first test case\n",
    "first_case = test_cases[0]\n",
    "print(\"Example test case:\")\n",
    "print(\"-\" * 40)\n",
    "for key, value in first_case.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§ª Running a Single Test Case\n",
    "\n",
    "Now let's run one test case and trace exactly what happens. Watch how the evaluator:\n",
    "1. Sends the query to the agent\n",
    "2. Captures the response and tool calls\n",
    "3. Runs each check against the response\n",
    "4. Produces a pass/fail result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ID: gs-001\n",
      "Query: What is our remote work policy?\n",
      "Passed: True\n",
      "Tools Used: ['vector_search']\n",
      "\n",
      "Checks:\n",
      "  - Tool Check: True\n",
      "  - Source Check: True\n",
      "  - Content Check: True\n",
      "  - Negative Check: True\n",
      "\n",
      "Response (first 500 chars):\n",
      "----------------------------------------\n",
      "Acme Corp Remote Work Policy (effective Jan 1, 2024; last updated Mar 15, 2024)\n",
      "\n",
      "- Remote-first: Employees may work fully remote, in-office, or hybrid based on preference and role requirements.\n",
      "- Core hours (availability expected): 10:00 AM â€“ 3:00 PM Pacific Time, Mondayâ€“Friday. Outside core hours, you can structure your day flexibly.\n",
      "- Home office support:\n",
      "  - Equipment provided: laptop (refreshed every 3 years), one 27\" monitor, keyboard/mouse, headset.\n",
      "  - Home office stipend: $500 annually (\n"
     ]
    }
   ],
   "source": [
    "# Run the first test case\n",
    "result = run_test_case(test_cases[0], verbose=True)\n",
    "\n",
    "print(f\"Test ID: {result.id}\")\n",
    "print(f\"Query: {result.query}\")\n",
    "print(f\"Passed: {result.passed}\")\n",
    "print(f\"Tools Used: {result.tools_used}\")\n",
    "print(f\"\\nChecks:\")\n",
    "print(f\"  - Tool Check: {result.tool_check}\")\n",
    "print(f\"  - Source Check: {result.source_check}\")\n",
    "print(f\"  - Content Check: {result.content_check}\")\n",
    "print(f\"  - Negative Check: {result.negative_check}\")\n",
    "\n",
    "if result.errors:\n",
    "    print(f\"\\nErrors: {result.errors}\")\n",
    "\n",
    "print(f\"\\nResponse (first 500 chars):\")\n",
    "print(\"-\" * 40)\n",
    "print(result.response[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”¬ Deep Dive: How Each Check Works\n",
    "\n",
    "Each test case runs multiple independent checks. Understanding these helps you write better tests.\n",
    "\n",
    "### The Four Types of Checks:\n",
    "\n",
    "| Check | What It Verifies | Why It Matters |\n",
    "|-------|-----------------|----------------|\n",
    "| **Tool Check** | Correct tools were used | Agent should route queries appropriately |\n",
    "| **Source Check** | Correct documents were cited | Agent should find relevant information |\n",
    "| **Content Check** | Key facts appear in response | Agent should extract and relay correct info |\n",
    "| **Negative Check** | Failure phrases are absent | Agent shouldn't hallucinate or give up |\n",
    "\n",
    "Let's see each check in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool Check: PASS\n",
      "Expected: ['vector_search']\n",
      "Actual: ['vector_search']\n",
      "\n",
      "Wrong Tool Check: FAIL\n",
      "Error: Missing tools: ['vector_search']\n"
     ]
    }
   ],
   "source": [
    "# Tool check example\n",
    "expected_tools = [\"vector_search\"]\n",
    "actual_tools = [\"vector_search\"]\n",
    "\n",
    "passed, error = check_tools(expected_tools, actual_tools)\n",
    "print(f\"Tool Check: {'PASS' if passed else 'FAIL'}\")\n",
    "print(f\"Expected: {expected_tools}\")\n",
    "print(f\"Actual: {actual_tools}\")\n",
    "\n",
    "# Try with wrong tools\n",
    "actual_wrong = [\"sql_query\"]\n",
    "passed, error = check_tools(expected_tools, actual_wrong)\n",
    "print(f\"\\nWrong Tool Check: {'PASS' if passed else 'FAIL'}\")\n",
    "print(f\"Error: {error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content Check: PASS\n",
      "Looking for: ['remote', 'core hours', '500']\n",
      "In response: Our remote work policy includes core hours from 10 AM to 3 PM and a $500 stipend....\n",
      "\n",
      "Missing Keyword Check: FAIL\n",
      "Error: Missing keywords: ['500']\n"
     ]
    }
   ],
   "source": [
    "# Content check example\n",
    "keywords = [\"remote\", \"core hours\", \"500\"]\n",
    "response = \"Our remote work policy includes core hours from 10 AM to 3 PM and a $500 stipend.\"\n",
    "\n",
    "passed, error = check_must_contain(keywords, response)\n",
    "print(f\"Content Check: {'PASS' if passed else 'FAIL'}\")\n",
    "print(f\"Looking for: {keywords}\")\n",
    "print(f\"In response: {response[:100]}...\")\n",
    "\n",
    "# Try with missing keyword\n",
    "response_missing = \"Our remote work policy includes core hours.\"\n",
    "passed, error = check_must_contain(keywords, response_missing)\n",
    "print(f\"\\nMissing Keyword Check: {'PASS' if passed else 'FAIL'}\")\n",
    "print(f\"Error: {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸƒ Running Multiple Test Cases\n",
    "\n",
    "In practice, you run the entire golden set to detect regressions. This is typically done:\n",
    "- **On every commit** â€” Part of your CI pipeline\n",
    "- **Before deployments** â€” Gate production releases\n",
    "- **After changes** â€” Verify nothing broke\n",
    "\n",
    "Let's run a subset to see what a typical run looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running gs-001: What is our remote work policy?...\n",
      "  âœ“ PASS\n",
      "\n",
      "Running gs-002: How much is the home office stipend?...\n",
      "  âœ“ PASS\n",
      "\n",
      "Running gs-003: What is our PTO policy?...\n",
      "  âœ“ PASS\n",
      "\n",
      "Running gs-004: How do I handle a production incident?...\n",
      "  âœ“ PASS\n",
      "\n",
      "Running gs-005: What are our pricing tiers?...\n",
      "  âœ“ PASS\n",
      "\n",
      "Results: 5/5 passed\n"
     ]
    }
   ],
   "source": [
    "# Run a subset of tests (first 5)\n",
    "results = []\n",
    "for tc in test_cases[:5]:\n",
    "    print(f\"Running {tc['id']}: {tc['query'][:40]}...\")\n",
    "    result = run_test_case(tc)\n",
    "    results.append(result)\n",
    "    status = \"âœ“ PASS\" if result.passed else \"âœ— FAIL\"\n",
    "    print(f\"  {status}\")\n",
    "    if not result.passed:\n",
    "        for err in result.errors:\n",
    "            print(f\"    - {err}\")\n",
    "    print()\n",
    "\n",
    "# Summary\n",
    "passed = sum(1 for r in results if r.passed)\n",
    "print(f\"Results: {passed}/{len(results)} passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœï¸ Writing Effective Test Cases\n",
    "\n",
    "A good golden set test case should be:\n",
    "\n",
    "### 1. **Specific and Verifiable**\n",
    "```yaml\n",
    "# âŒ Bad: Too vague\n",
    "must_contain: [\"policy\"]\n",
    "\n",
    "# âœ… Good: Specific, verifiable facts\n",
    "must_contain: [\"30-day\", \"refund\", \"annual plans\"]\n",
    "```\n",
    "\n",
    "### 2. **Representative of Real Queries**\n",
    "Base tests on actual user questions, not hypothetical edge cases (save those for Stage 2).\n",
    "\n",
    "### 3. **Include Negative Checks**\n",
    "Catch hallucinations and false negatives:\n",
    "```yaml\n",
    "must_not_contain: [\"I don't know\", \"I cannot\", \"no information\"]\n",
    "```\n",
    "\n",
    "Let's create and test a new case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing new case:\n",
      "Query: What are the code review requirements?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define a new test case\n",
    "new_test = {\n",
    "    \"id\": \"gs-custom-001\",\n",
    "    \"category\": \"vector_search\",\n",
    "    \"query\": \"What are the code review requirements?\",\n",
    "    \"expected_tools\": [\"vector_search\"],\n",
    "    \"expected_sources\": [\"code_review_standards.md\"],\n",
    "    \"must_contain\": [\"review\", \"approval\"],\n",
    "    \"must_not_contain\": [\"I don't know\"],\n",
    "}\n",
    "\n",
    "# Run it\n",
    "print(\"Testing new case:\")\n",
    "print(f\"Query: {new_test['query']}\")\n",
    "print()\n",
    "\n",
    "result = run_test_case(new_test)\n",
    "print(f\"Passed: {result.passed}\")\n",
    "print(f\"Tools used: {result.tools_used}\")\n",
    "if result.errors:\n",
    "    print(f\"Errors: {result.errors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Best Practices Checklist\n",
    "\n",
    "| Category | Recommendation |\n",
    "|----------|---------------|\n",
    "| **Size** | 10-50 test cases (quality over quantity) |\n",
    "| **Run time** | Should complete in < 5 minutes |\n",
    "| **Coverage** | At least 2-3 cases per tool/capability |\n",
    "| **Updates** | Add cases when you find production bugs |\n",
    "\n",
    "### Anti-Patterns to Avoid\n",
    "\n",
    "âŒ **Testing exact wording** â€” AI responses vary, test for meaning  \n",
    "âŒ **Too many test cases** â€” Diminishing returns, slow runs  \n",
    "âŒ **Vague must_contain** â€” \"answer\" is not specific enough  \n",
    "âŒ **No negative checks** â€” You'll miss hallucinations  \n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ Key Takeaways\n",
    "\n",
    "1. **Golden sets are your foundation** â€” Without them, you don't know if your agent works\n",
    "2. **They test constraints, not exact outputs** â€” Use `must_contain`, `expected_tools`, etc.\n",
    "3. **Keep them small and fast** â€” 10-50 cases that run in minutes\n",
    "4. **Run on every change** â€” They're your first line of defense\n",
    "5. **Base them on real queries** â€” Use actual user questions from production\n",
    "\n",
    "---\n",
    "\n",
    "## â­ï¸ What's Next?\n",
    "\n",
    "Golden sets tell you if things are broken, but they don't tell you about **coverage**. \n",
    "\n",
    "- Are you testing all the different types of queries users ask?\n",
    "- What about edge cases and ambiguous questions?\n",
    "- How do you know which categories need more testing?\n",
    "\n",
    "That's what **Stage 2: Labeled Scenarios** addresses:\n",
    "\n",
    "```bash\n",
    "cd ../stage_2_labeled_scenarios\n",
    "uv run jupyter notebook walkthrough.ipynb\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
